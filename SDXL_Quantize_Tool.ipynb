{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dze5rHLFQLRb"
      },
      "source": [
        "## 1. Git Clone the repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mg_Hb6UHgNCq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "else:\n",
        "    print(\"Google Drive is already mounted.\")\n",
        "\n",
        "%cd /content\n",
        "\n",
        "# 2. Handle Repository (Clone or Update)\n",
        "repo_dir = \"/content/SDXL_GGUF_Quantize_Tool\"\n",
        "repo_url = \"https://github.com/magekinnarus/SDXL_GGUF_Quantize_Tool.git\"\n",
        "\n",
        "if not os.path.exists(repo_dir):\n",
        "    print(\"Cloning repository...\")\n",
        "    !git clone {repo_url} {repo_dir}\n",
        "else:\n",
        "    print(\"Repository already exists. Pulling latest updates...\")\n",
        "    %cd {repo_dir}\n",
        "    !git pull\n",
        "\n",
        "# 3. Finalize directory location\n",
        "%cd {repo_dir}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xh8C59hcQVHS"
      },
      "source": [
        "### 1.1 Create .env (Optional) or you can upload yours to /content folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNHdl8c0h0AA",
        "outputId": "209c7bf0-7723-4b8e-e0ed-42c9904cc539"
      },
      "outputs": [],
      "source": [
        "%%writefile /content/.env\n",
        "HUGGINGFACE_TOKEN=##your_huggingface_token##\n",
        "CIVITAI_TOKEN=##your_civitai_token##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnwckChvQ7gy"
      },
      "source": [
        "## 2. Download models from CivitAI. I am using a model catalogue json file. You can modify and upload your own json file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XUTwTTTRV4C"
      },
      "source": [
        "### 2.1 Inatall Aria2 and download the model catalogue json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmPtQL_Pi5E-"
      },
      "outputs": [],
      "source": [
        "!apt -y install -qq aria2\n",
        "\n",
        "# Ensure dotenv is installed\n",
        "try:\n",
        "    import dotenv\n",
        "except ImportError:\n",
        "    print(\"Installing python-dotenv...\")\n",
        "    !pip install python-dotenv\n",
        "\n",
        "import shutil\n",
        "import subprocess\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# Define the path to your .env file (you can adjust this if your .env file is located elsewhere)\n",
        "token_path = \"/content\"\n",
        "\n",
        "# Load environment variables from the .env file\n",
        "# This will look for a .env file in the current working directory, or you can specify the path\n",
        "load_dotenv(dotenv_path=os.path.join(token_path, \".env\"))\n",
        "\n",
        "# Get the Hugging Face token from environment variables\n",
        "HF_TOKEN = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
        "\n",
        "# Load models_configs file\n",
        "!wget -P /content/models https://huggingface.co/Old-Fisherman/SDXL_Models/resolve/main/civit_models_config.json\n",
        "\n",
        "#Clear log printout\n",
        "clear_output(wait=False)\n",
        "print(\"‚úÖ all processes completed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwDT46BoRceh"
      },
      "source": [
        "### 2.2 Download from CivitAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NgsPdIvjTRm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import subprocess\n",
        "from dotenv import load_dotenv\n",
        "from IPython.display import clear_output\n",
        "\n",
        "# 1. Load Model Configurations from both Public and Private files\n",
        "model_path = \"/content/models\"\n",
        "config_files = ['civit_models_config.json', 'civit_models_P1_config.json']\n",
        "ALL_MODELS = []\n",
        "\n",
        "for file_name in config_files:\n",
        "    full_path = os.path.join(model_path, file_name)\n",
        "    if os.path.exists(full_path):\n",
        "        with open(full_path, 'r') as f:\n",
        "            data = json.load(f)\n",
        "            # Extract models from Categories (Checkpoints/LoRA) and Sub-types (SDXL/Pony/etc)\n",
        "            for category in data.values():\n",
        "                for model_list in category.values():\n",
        "                    ALL_MODELS.extend(model_list)\n",
        "        print(f\"‚úÖ Loaded: {file_name}\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Warning: {file_name} not found.\")\n",
        "\n",
        "# 2. Create Model Directories based on the 'dir' keys in the JSON\n",
        "# This automatically handles 'checkpoints', 'loras', and 'unet' folders\n",
        "unique_dirs = set(m['dir'] for m in ALL_MODELS)\n",
        "for d in unique_dirs:\n",
        "    os.makedirs(os.path.join(model_path, d), exist_ok=True)\n",
        "print(f\"Directories verified: {', '.join(unique_dirs)}\")\n",
        "\n",
        "# 3. Define the download script\n",
        "def download_model(selector):\n",
        "    # Find the model by 'nr' (int) or 'alias' (str)\n",
        "    config = next((m for m in ALL_MODELS if m['nr'] == selector or m['alias'] == selector), None)\n",
        "\n",
        "    if not config:\n",
        "        print(f\"‚ùå Configuration not found for: {selector}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüöÄ Starting download: {config['name']} ({config['alias']})\")\n",
        "\n",
        "    base_url = \"https://civitai.com/api/download/models/\"\n",
        "    # Ensure environment variables are loaded for the token\n",
        "    load_dotenv(os.path.join(\"/content\", \".env\"))\n",
        "    CIVITAI_TOKEN = os.getenv('CIVITAI_TOKEN', '')\n",
        "\n",
        "    url = f\"{base_url}{config['id']}?token={CIVITAI_TOKEN}\"\n",
        "    download_dir = os.path.join(model_path, config['dir'])\n",
        "\n",
        "    try:\n",
        "        command = [\n",
        "            'aria2c', '--console-log-level=warn', '-c', '-x', '16', '-s', '16', '-k', '1M',\n",
        "            '--dir', download_dir, '--out', config['name'], url\n",
        "        ]\n",
        "        subprocess.check_call(command)\n",
        "        print(f\"‚úÖ Download completed: {config['name']}\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"üõë Error downloading {config['name']}: {e}\")\n",
        "\n",
        "# 4. Select Models (Use Number or Alias)\n",
        "SELECTED_MODELS = [\n",
        "    \"innovision\", \"realcartoon_xl\", \"juggernaut\", \"blendermix\"\n",
        "]\n",
        "\n",
        "print(\"Starting download process for selected models...\")\n",
        "for selector in SELECTED_MODELS:\n",
        "    download_model(selector)\n",
        "\n",
        "# Clear log printout\n",
        "clear_output(wait=False)\n",
        "print(\"‚úÖ All selected model downloads completed successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LfNZ-4ySBpK"
      },
      "source": [
        "## 3. Run the app!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "id": "hnyT5fg4mCSr",
        "outputId": "6f7b0542-342c-4e08-e8a6-d3d2e4be1112"
      },
      "outputs": [],
      "source": [
        "# --- RUNNING THE UI ---\n",
        "!pip install -q -r requirements-gradio.txt\n",
        "\n",
        "import os\n",
        "import gguf\n",
        "import app_gradio\n",
        "\n",
        "# 1. Ensure we are in the repo directory\n",
        "%cd /content/SDXL_GGUF_Quantize_Tool\n",
        "\n",
        "# 3. Launch strictly within the Colab iframe\n",
        "print(\"\\n--- Launching SDXL GGUF Quantizer (Local Only) ---\")\n",
        "\n",
        "app_gradio.demo.launch(\n",
        "    share=True,      # No public link generated\n",
        "    inline=True,      # Displays inside this Colab cell\n",
        "    debug=True,       # Helpful for tracking quantization progress/errors\n",
        "    height=800\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
